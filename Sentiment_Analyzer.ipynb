{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPm+D4+47te7BIpRQEOKFyj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FrankT990/Sent_Analyzer/blob/main/Sentiment_Analyzer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests\n",
        "!pip install newsapi-python\n",
        "!pip install finnhub-python\n",
        "!pip install scikit-learn\n",
        "import finnhub\n",
        "import time\n",
        "import yfinance as yf\n",
        "import requests\n",
        "from datetime import datetime, timedelta\n",
        "from newsapi import NewsApiClient\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "metadata": {
        "id": "ftklDb5c_5hQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This code block is for functions that help with testing / printing outputs\n",
        "\n",
        "# uses finnhub api\n",
        "# Example of req:\n",
        "# finnhub_client.company_news('SPY', _from=\"2023-09-04\", to=\"2024-09-04\")\n",
        "def print_headlines_datetimes(req):\n",
        "  for article in req:\n",
        "    print(datetime.utcfromtimestamp(article['datetime']).strftime('%Y-%m-%d'))\n",
        "\n",
        "# How to make df:\n",
        "# stock = yf.Ticker(\"SPY\")\n",
        "# hist = stock.history(period=\"1y\")\n",
        "# df = pd.DataFrame(hist)\n",
        "def print_SPY_performance_datetimes(df):\n",
        "  for ts, row in df.iterrows():\n",
        "    print(ts.strftime('%Y-%m-%d'))\n",
        "\n",
        "def one_year_ago():\n",
        "  return (datetime.now() - timedelta(days=365)).strftime('%Y-%m-%d')\n",
        "\n",
        "def date_now():\n",
        "  return datetime.now().strftime('%Y-%m-%d')\n",
        "\n",
        "# unix_time_stamp -> YYYY-MM-DD\n",
        "def unix_timestamp_to_date(unix_timestamp):\n",
        "  return datetime.utcfromtimestamp(unix_timestamp).strftime('%Y-%m-%d ')\n",
        "\n"
      ],
      "metadata": {
        "id": "F0n74Ad9AQFm"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from_date and to_date in format of YYYY-MM-DD\n",
        "# ex: 2024-09-04\n",
        "def write_headlines(tkr, from_date, to_date, finnhub_api_key):\n",
        "    try:\n",
        "      finnhub_client = finnhub.Client(api_key=finnhub_api_key)\n",
        "      df = pd.DataFrame()\n",
        "      news = finnhub_client.company_news(tkr, _from=from_date, to=to_date)\n",
        "      for article in news:\n",
        "        date = unix_timestamp_to_date(article['datetime'])\n",
        "        new_row = pd.DataFrame({\n",
        "        'date': [date],\n",
        "        'headline': [article['headline']]\n",
        "        })\n",
        "        df = pd.concat([df, new_row], ignore_index=True)\n",
        "      return df\n",
        "    except:\n",
        "      return 'err'\n",
        "\n",
        "def write_performance_dict(tkr):\n",
        "  try:\n",
        "    perf_dict = {}\n",
        "    stock = yf.Ticker(tkr)\n",
        "    hist = stock.history(period=\"1y\")\n",
        "    yf_df = pd.DataFrame(hist)\n",
        "    for ts, row in yf_df.iterrows():\n",
        "      info = row.to_dict()\n",
        "      perc_change = (info['Close'] - info['Open']) / info['Open']\n",
        "      perf_dict[ts.strftime('%Y-%m-%d')] = perc_change\n",
        "    return perf_dict\n",
        "  except:\n",
        "    return \"err\"\n",
        "\n",
        "def add_data(perf_dict, headlines_df):\n",
        "  try:\n",
        "    df = pd.DataFrame()\n",
        "    # main_dict = {}\n",
        "    for i, row in headlines_df.iterrows():\n",
        "      date = row['date'].strip()\n",
        "      headline = row['headline']\n",
        "      pc = perf_dict.get(date, 'Undefined key')\n",
        "      if(type(pc) == float):\n",
        "        new_row = pd.DataFrame({\n",
        "        'headline': [headline],\n",
        "        'percent_change': [pc]\n",
        "        })\n",
        "        # main_dict[headline] = pc\n",
        "        df = pd.concat([df, new_row], ignore_index=True)\n",
        "    return df\n",
        "  except:\n",
        "    return pd.DataFrame()\n",
        "\n",
        "def make_model(df):\n",
        "  # FROM DOCS\n",
        "  vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
        "  X = vectorizer.fit_transform(df['headline'])\n",
        "\n",
        "  y = df['percent_change'].values\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "  model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "  model.fit(X_train, y_train)\n",
        "\n",
        "  y_pred = model.predict(X_test)\n",
        "  mse = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "  return [model, vectorizer, mse]\n"
      ],
      "metadata": {
        "id": "Rf6M9G78ffSa"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def prepare_df(stocks, finnhub_key):\n",
        "  df = pd.DataFrame()\n",
        "  for stock in stocks:\n",
        "    perf_dict = write_performance_dict(tkr=stock)\n",
        "    headlines_df = write_headlines(tkr=stock, from_date=one_year_ago(), to_date=date_now(), finnhub_api_key=finnhub_key)\n",
        "    if (type(perf_dict) != str and type(headlines_df) != str):\n",
        "      df = pd.concat([df, add_data(perf_dict, headlines_df)], ignore_index=True)\n",
        "  return df\n",
        "\n",
        "def get_stock_input():\n",
        "  print(chr(27) + \"[2J\")\n",
        "  default_stocks_list=['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'META', 'TSLA', 'NVDA']\n",
        "  print('Would you like to train the model using your own stock list? (y/n) '+'\\n'+'(Note: Acceptable size of stock list is dependent on API key)')\n",
        "  inp = input()\n",
        "  match inp:\n",
        "    case 'y':\n",
        "      print('Please input stocks in Python list format\\nex: [\\'AAPL\\', \\'MSFT\\', \\'GOOGL\\', \\'AMZN\\', \\'META\\', \\'TSLA\\', \\'NVDA\\']')\n",
        "      stocks = list(input())\n",
        "      return stocks\n",
        "      print('Creating model using custom stock list...')\n",
        "    case 'n':\n",
        "      print('Creating model using default stock list...')\n",
        "      return default_stocks_list\n",
        "    case default:\n",
        "      print('Invalid input')\n",
        "      get_stock_input()\n",
        "\n",
        "def predict_headline(model, vectorizer):\n",
        "  print('Input headline to test\\n')\n",
        "  headline = input()\n",
        "  headline_vector = vectorizer.transform([headline])\n",
        "  pc = model.predict(headline_vector)\n",
        "  if pc[0] > 0:\n",
        "    print('Market Sentiment: Bullish (Estimated percent change: + %' + str(pc[0]*100)+')\\n')\n",
        "  else:\n",
        "    print('Market Sentiment: Bearish (Estimated percent change: - %' + str(pc[0]*100)+')\\n')\n",
        "\n",
        "def control_flow():\n",
        "  print('1. Test Another Headline\\n2. Re-train model on new stock list\\n')\n",
        "  inp = input()\n",
        "  match inp:\n",
        "    case '1':\n",
        "      predict_headline(data[0], data[1])\n",
        "    case '2':\n",
        "      stocks = get_stock_input()\n",
        "      df = prepare_df(stocks, finnhub_key)\n",
        "      data = make_model(df)\n",
        "      print('Model created!\\nMSE: '+str(data[2]))\n",
        "    case default:\n",
        "      print('Invalid input')\n",
        "      control_flow()\n",
        "  control_flow()\n"
      ],
      "metadata": {
        "id": "Il0o3ikiMzgA"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FRONT END\n",
        "# Please make sure to run preceeding code blocks this code block\n",
        "# \"\"\n",
        "\n",
        "print('Please input a finnhub API key: \\n(You can get one for free at https://finnhub.io/)')\n",
        "finnhub_key = input()\n",
        "stocks = get_stock_input()\n",
        "df = prepare_df(stocks, finnhub_key)\n",
        "data = make_model(df)\n",
        "print('Model created!\\nMSE: '+str(data[2]))\n",
        "predict_headline(data[0], data[1])\n",
        "control_flow()"
      ],
      "metadata": {
        "id": "rZGHBk0Krcqf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}