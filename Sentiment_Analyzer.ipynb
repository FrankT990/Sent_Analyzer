{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOYIg9aFa6GziFjIFaHkz/U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FrankT990/Sent_Analyzer/blob/main/Sentiment_Analyzer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests\n",
        "!pip install newsapi-python\n",
        "!pip install finnhub-python\n",
        "!pip install scikit-learn\n",
        "import finnhub\n",
        "import time\n",
        "import yfinance as yf\n",
        "import requests\n",
        "from datetime import datetime, timedelta\n",
        "from newsapi import NewsApiClient\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "metadata": {
        "id": "ftklDb5c_5hQ",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9efd966-3ad0-4c12-c132-922e6f8756e1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n",
            "Collecting newsapi-python\n",
            "  Downloading newsapi_python-0.2.7-py2.py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: requests<3.0.0 in /usr/local/lib/python3.10/dist-packages (from newsapi-python) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0->newsapi-python) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0->newsapi-python) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0->newsapi-python) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0->newsapi-python) (2024.8.30)\n",
            "Downloading newsapi_python-0.2.7-py2.py3-none-any.whl (7.9 kB)\n",
            "Installing collected packages: newsapi-python\n",
            "Successfully installed newsapi-python-0.2.7\n",
            "Collecting finnhub-python\n",
            "  Downloading finnhub_python-2.4.20-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.10/dist-packages (from finnhub-python) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->finnhub-python) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->finnhub-python) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->finnhub-python) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->finnhub-python) (2024.8.30)\n",
            "Downloading finnhub_python-2.4.20-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: finnhub-python\n",
            "Successfully installed finnhub-python-2.4.20\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This code block is for functions that help with testing / printing outputs\n",
        "\n",
        "# uses finnhub api\n",
        "# Example of req:\n",
        "# finnhub_client.company_news('SPY', _from=\"2023-09-04\", to=\"2024-09-04\")\n",
        "def print_headlines_datetimes(req):\n",
        "  for article in req:\n",
        "    print(datetime.utcfromtimestamp(article['datetime']).strftime('%Y-%m-%d'))\n",
        "\n",
        "# How to make df:\n",
        "# stock = yf.Ticker(\"SPY\")\n",
        "# hist = stock.history(period=\"1y\")\n",
        "# df = pd.DataFrame(hist)\n",
        "def print_SPY_performance_datetimes(df):\n",
        "  for ts, row in df.iterrows():\n",
        "    print(ts.strftime('%Y-%m-%d'))\n",
        "\n",
        "def one_year_ago():\n",
        "  return (datetime.now() - timedelta(days=365)).strftime('%Y-%m-%d')\n",
        "\n",
        "def date_now():\n",
        "  return datetime.now().strftime('%Y-%m-%d')\n",
        "\n",
        "# unix_time_stamp -> YYYY-MM-DD\n",
        "def unix_timestamp_to_date(unix_timestamp):\n",
        "  return datetime.utcfromtimestamp(unix_timestamp).strftime('%Y-%m-%d ')\n",
        "\n"
      ],
      "metadata": {
        "id": "F0n74Ad9AQFm"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from_date and to_date in format of YYYY-MM-DD\n",
        "# ex: 2024-09-04\n",
        "def write_headlines(tkr, from_date, to_date, finnhub_api_key):\n",
        "    try:\n",
        "      finnhub_client = finnhub.Client(api_key=finnhub_api_key)\n",
        "      df = pd.DataFrame()\n",
        "      news = finnhub_client.company_news(tkr, _from=from_date, to=to_date)\n",
        "      for article in news:\n",
        "        date = unix_timestamp_to_date(article['datetime'])\n",
        "        new_row = pd.DataFrame({\n",
        "        'date': [date],\n",
        "        'headline': [article['headline']]\n",
        "        })\n",
        "        df = pd.concat([df, new_row], ignore_index=True)\n",
        "      return df\n",
        "    except:\n",
        "      return 'err'\n",
        "\n",
        "def write_performance_dict(tkr):\n",
        "  try:\n",
        "    perf_dict = {}\n",
        "    stock = yf.Ticker(tkr)\n",
        "    hist = stock.history(period=\"1y\")\n",
        "    yf_df = pd.DataFrame(hist)\n",
        "    for ts, row in yf_df.iterrows():\n",
        "      info = row.to_dict()\n",
        "      perc_change = (info['Close'] - info['Open']) / info['Open']\n",
        "      perf_dict[ts.strftime('%Y-%m-%d')] = perc_change\n",
        "    return perf_dict\n",
        "  except:\n",
        "    return \"err\"\n",
        "\n",
        "def add_data(perf_dict, headlines_df):\n",
        "  try:\n",
        "    df = pd.DataFrame()\n",
        "    # main_dict = {}\n",
        "    for i, row in headlines_df.iterrows():\n",
        "      date = row['date'].strip()\n",
        "      headline = row['headline']\n",
        "      pc = perf_dict.get(date, 'Undefined key')\n",
        "      if(type(pc) == float):\n",
        "        new_row = pd.DataFrame({\n",
        "        'headline': [headline],\n",
        "        'percent_change': [pc]\n",
        "        })\n",
        "        # main_dict[headline] = pc\n",
        "        df = pd.concat([df, new_row], ignore_index=True)\n",
        "    return df\n",
        "  except:\n",
        "    return pd.DataFrame()\n",
        "\n",
        "def make_model(df):\n",
        "  # FROM DOCS\n",
        "  vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
        "  X = vectorizer.fit_transform(df['headline'])\n",
        "\n",
        "  y = df['percent_change'].values\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "  model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "  model.fit(X_train, y_train)\n",
        "\n",
        "  y_pred = model.predict(X_test)\n",
        "  mse = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "  return [model, vectorizer, mse]\n"
      ],
      "metadata": {
        "id": "Rf6M9G78ffSa"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def prepare_df(stocks, finnhub_key):\n",
        "  df = pd.DataFrame()\n",
        "  for stock in stocks:\n",
        "    perf_dict = write_performance_dict(tkr=stock)\n",
        "    headlines_df = write_headlines(tkr=stock, from_date=one_year_ago(), to_date=date_now(), finnhub_api_key=finnhub_key)\n",
        "    if (type(perf_dict) != str and type(headlines_df) != str):\n",
        "      df = pd.concat([df, add_data(perf_dict, headlines_df)], ignore_index=True)\n",
        "  return df\n",
        "\n",
        "def get_stock_input():\n",
        "  default_stocks_list=['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'META', 'TSLA', 'NVDA']\n",
        "  print('Would you like to train the model using your own stock list? (y/n) '+'\\n'+'(Note: Acceptable size of stock list is dependent on API key)')\n",
        "  inp = input()\n",
        "  match inp:\n",
        "    case 'y':\n",
        "      print('Please input stocks in Python list format\\nex: [\\'AAPL\\', \\'MSFT\\', \\'GOOGL\\', \\'AMZN\\', \\'META\\', \\'TSLA\\', \\'NVDA\\']')\n",
        "      stocks = list(input())\n",
        "      return stocks\n",
        "      print('Creating model using custom stock list...')\n",
        "    case 'n':\n",
        "      print('Creating model using default stock list...')\n",
        "      return default_stocks_list\n",
        "    case default:\n",
        "      print('Invalid input')\n",
        "      get_stock_input()\n",
        "\n",
        "def predict_headline(model, vectorizer):\n",
        "  print('Input headline to test\\n')\n",
        "  headline = input()\n",
        "  headline_vector = vectorizer.transform([headline])\n",
        "  pc = model.predict(headline_vector)\n",
        "  if pc[0] > 0:\n",
        "    print('Market Sentiment: Bullish (Estimated percent change: + %' + str(pc[0]*100)+')\\n')\n",
        "  else:\n",
        "    print('Market Sentiment: Bearish (Estimated percent change: - %' + str(pc[0]*100)[11:]+')\\n')\n",
        "\n",
        "def control_flow(data):\n",
        "  print('1. Test Another Headline\\n2. Re-train model on new stock list\\n')\n",
        "  inp = input()\n",
        "  match inp:\n",
        "    case '1':\n",
        "      predict_headline(data[0], data[1])\n",
        "    case '2':\n",
        "      stocks = get_stock_input()\n",
        "      df = prepare_df(stocks, finnhub_key)\n",
        "      data = make_model(df)\n",
        "      print('Model created!\\nMSE: '+str(data[2]))\n",
        "    case default:\n",
        "      print('Invalid input')\n",
        "      control_flow(data)\n",
        "  control_flow(data)\n"
      ],
      "metadata": {
        "id": "Il0o3ikiMzgA"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FRONT END\n",
        "# Please make sure to run preceeding code blocks this code block\n",
        "# \"\"\n",
        "\n",
        "print('Please input a finnhub API key: \\n(You can get one for free at https://finnhub.io/)')\n",
        "finnhub_key = input()\n",
        "stocks = get_stock_input()\n",
        "df = prepare_df(stocks, finnhub_key)\n",
        "data = make_model(df)\n",
        "print('Model created!\\nMSE: '+str(data[2]))\n",
        "predict_headline(data[0], data[1])\n",
        "control_flow(data)"
      ],
      "metadata": {
        "id": "rZGHBk0Krcqf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcb26350-5009-425b-bd69-e0d189390cde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please input a finnhub API key: \n",
            "(You can get one for free at https://finnhub.io/)\n",
            "cr140apr01qo0i56tudgcr140apr01qo0i56tue0\n",
            "Would you like to train the model using your own stock list? (y/n) \n",
            "(Note: Acceptable size of stock list is dependent on API key)\n",
            "n\n",
            "Creating model using default stock list...\n",
            "Model created!\n",
            "MSE: 0.0003373527079582977\n",
            "Input headline to test\n",
            "\n"
          ]
        }
      ]
    }
  ]
}